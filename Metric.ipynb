{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e399e5d7",
   "metadata": {},
   "source": [
    "# ROUGE score(ดูคำซ้ำ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba9d803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 P: 0.0 R: 0.0 F1: 0.0\n",
      "rouge2 P: 0.0 R: 0.0 F1: 0.0\n",
      "rougeL P: 0 R: 0 F1: 0\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(\n",
    "    ['rouge1', 'rouge2', 'rougeL'],\n",
    "    use_stemmer=False\n",
    ")\n",
    "\n",
    "reference = \"เนื้อหาจากแหล่งข้อมูลนี้เน้นย้ำถึง ความสำคัญของการตื่นเช้า เพื่อเพิ่มประสิทธิภาพในการเรียนและการทำงานให้สูงสุด ผู้พูดได้โต้แย้งความเชื่อเรื่องการเป็นคนถนัดทำงานกลางคืน โดยชี้ให้เห็นว่า การสะสมของฮอร์โมนความเหนื่อยล้า ตลอดทั้งวันจะทำให้การอ่านหนังสือในช่วงดึกไม่มีคุณภาพเท่าที่ควร การปรับเปลี่ยนพฤติกรรมมา ตื่นนอนในช่วงเช้ามืด เช่น เวลาตีสามหรือตีสี่ จะช่วยให้ร่างกายมีความพร้อมและมีสมาธิในการรับข้อมูลใหม่ได้ดีกว่า การมีวินัยในกิจวัตรยามเช้าถูกนำเสนอว่าเป็น กุญแจสำคัญสู่ความสำเร็จ ทางการศึกษา ดังเช่นประสบการณ์ตรงของผู้พูดที่สามารถสอบติดคณะแพทยศาสตร์ได้ ผลลัพธ์ที่ได้จากการทำงานอย่างมีคุณภาพในช่วงเช้าจึง มีค่ามากกว่าการฝืนอ่านหนังสือ ในขณะที่ร่างกายอ่อนล้าอย่างเทียบไม่ได้\"\n",
    "prediction = '''การตื่นเช้าทำงานดีกว่าการนอนตื่นสาย การนอนหลับไม่เพียงพอทำให้ร่างกายเหนื่อยล้า\n",
    "ฮอร์โมนอะดรีนาลินช่วยกระตุ้นร่างกายให้ตื่นตัว การนอนหลับที่มีคุณภาพสำคัญต่อการฟื้นฟูร่างกาย\n",
    "การตื่นเช้าช่วยเพิ่มประสิทธิภาพในการทำงานและทำให้มีเวลามากขึ้นในการทำกิจกรรมอื่นๆ'''\n",
    "\n",
    "scores = scorer.score(reference, prediction)\n",
    "\n",
    "for k, v in scores.items():\n",
    "    print(\n",
    "        k,\n",
    "        \"P:\", round(v.precision, 3),\n",
    "        \"R:\", round(v.recall, 3),\n",
    "        \"F1:\", round(v.fmeasure, 3)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ff8c8",
   "metadata": {},
   "source": [
    "ROUGE ไม่ดูความหมาย ดูแค่คำตรง\n",
    "สาเหตุที่เป็นไปได้ (และพบบ่อยมาก)\n",
    "-ใช้คำพ้อง / เรียบเรียงใหม่หมด\n",
    "-ภาษาไทย (word segmentation ต่าง)\n",
    "-Reference มาจาก LLM (NotebookLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea0698",
   "metadata": {},
   "source": [
    "# BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b910c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "refsNoteLM = [\"เนื้อหาจากแหล่งข้อมูลนี้เน้นย้ำถึง ความสำคัญของการตื่นเช้า เพื่อเพิ่มประสิทธิภาพในการเรียนและการทำงานให้สูงสุด ผู้พูดได้โต้แย้งความเชื่อเรื่องการเป็นคนถนัดทำงานกลางคืน โดยชี้ให้เห็นว่า การสะสมของฮอร์โมนความเหนื่อยล้า ตลอดทั้งวันจะทำให้การอ่านหนังสือในช่วงดึกไม่มีคุณภาพเท่าที่ควร การปรับเปลี่ยนพฤติกรรมมา ตื่นนอนในช่วงเช้ามืด เช่น เวลาตีสามหรือตีสี่ จะช่วยให้ร่างกายมีความพร้อมและมีสมาธิในการรับข้อมูลใหม่ได้ดีกว่า การมีวินัยในกิจวัตรยามเช้าถูกนำเสนอว่าเป็น กุญแจสำคัญสู่ความสำเร็จ ทางการศึกษา ดังเช่นประสบการณ์ตรงของผู้พูดที่สามารถสอบติดคณะแพทยศาสตร์ได้ ผลลัพธ์ที่ได้จากการทำงานอย่างมีคุณภาพในช่วงเช้าจึง มีค่ามากกว่าการฝืนอ่านหนังสือ ในขณะที่ร่างกายอ่อนล้าอย่างเทียบไม่ได้\"]\n",
    "\n",
    "refsNoteGPT = [\"เนื้อหาชี้ให้เห็นว่า การจัดการเวลาในการทำงานและการเรียนรู้มีความสำคัญอย่างยิ่งต่อประสิทธิภาพงาน โดยเฉพาะการเลือกที่จะตื่นเช้าเพื่อใช้ช่วงเวลาที่ร่างกายและสมองยังสดชื่น ซึ่งฮอร์โมนในร่างกายอยู่ในระดับที่เหมาะสมที่สุดสำหรับการทำงานที่ต้องใช้ความคิดและสมาธิ ขณะที่การทำงานในช่วงดึกหลังจากเหนื่อยมาทั้งวันนั้นจะส่งผลให้ประสิทธิภาพลดลงอย่างมาก โดยรวมแล้ว ผู้พูดเน้นย้ำว่า การวางแผนชีวิตและกิจกรรมให้สอดคล้องกับวงจรฮอร์โมนและช่วงเวลาที่ร่างกายพร้อมที่สุด จะช่วยให้ทำงานและเรียนรู้ได้ดีขึ้นและมีคุณภาพมากขึ้น\"]\n",
    "\n",
    "refsNotta = ['''การสนทนานี้เป็นการแลกเปลี่ยนความคิดเห็นเกี่ยวกับการจัดการเวลาและนิสัยการเรียนที่มีประสิทธิภาพ โดยผู้พูดหลักได้เน้นย้ำถึงความสำคัญของการตื่นเช้าเพื่อการทำงานและการเรียนที่มีคุณภาพ\n",
    "ผู้พูดหลักได้แนะนำให้ตื่นเช้าและอ่านหนังสือเป็นเวลา 12 ชั่วโมง โดยเขาได้เปรียบเทียบคนที่ทำงานกลางคืนว่าเป็น \"หมาป่ากลางคืน\" และ \"นกฮูก\" ที่ต้องทำงานในช่วงเวลาที่ไม่เหมาะสม เขาได้วิพากษ์วิจารณ์การตื่นเที่ยงว่าเป็นสิ่งที่ไร้สาระ และเสนอแนะว่าการตื่นเช้ามาทำงานจะดีกว่ามาก\n",
    "ในส่วนของการอธิบายทางวิทยาศาสตร์ ผู้พูดได้กล่าวถึงสาร Adenosine ซึ่งเป็นสารที่จะเพิ่มขึ้นเรื่อยๆ เมื่อตื่น และจะลดลงเมื่อนอน เขาได้อธิบายว่าการอ่านหนังสือตอนกลางคืนนั้นไม่เหมาะสม เนื่องจากฮอร์โมนต่างๆ จะมีผลต่อประสิทธิภาพการเรียน\n",
    "ผู้พูดได้เล่าประสบการณ์ส่วนตัวว่าหลังจากไปโรงเรียนทั้งวันแล้ว ร่างกายจะเหนื่อยล้ามาก หากต้องมานั่งอ่านหนังสือตอนกลางคืนอีกจะทำให้ประสิทธิภาพลดลง เขาจึงแนะนำให้ตื่นเช้ามาอ่านหนังสือแทน ซึ่งจะช่วยได้มาก\n",
    "ในตอนท้าย ผู้พูดได้ยกตัวอย่างความสำเร็จของตนเองโดยกล่าวว่าเขาสามารถเข้าเรียนที่ Cambridge ได้เพราะการตื่นเช้ามาอ่านหนังสือ''']\n",
    "\n",
    "refsGemini = ['''วิดีโอนี้เป็นการแนะนำแนวทางสำหรับคนที่อยากเริ่มต้นเป็นคนใหม่ในปีใหม่ โดยเฉพาะคนที่อยากเรียนเก่งขึ้น โดยเน้นความสำคัญของการ \"ตื่นเช้า\" มาอ่านหนังสือครับ สรุปใจความสำคัญได้ดังนี้:\n",
    "การตื่นเช้าเพื่อสร้างคุณภาพ: ผู้พูดแนะนำให้ตื่นช่วงตี 3 หรือ ตี 4 เพื่อมาอ่านหนังสือ [00:00] ซึ่งจะมีประสิทธิภาพมากกว่าการเป็น \"หมาป่ากลางคืน\" ที่ทำงานหรืออ่านหนังสือจนถึงตี 2-3 แล้วไปตื่นตอนเที่ยง [00:10]\n",
    "ผลกระทบของฮอร์โมนความเหนื่อยล้า: มีการอธิบายถึงฮอร์โมน (อะดีโนซีน) ที่จะสะสมความเหนื่อยล้าเพิ่มขึ้นเรื่อย ๆ ระหว่างวัน [00:22] การฝืนอ่านหนังสือตอนกลางคืนหลังจากที่เหนื่อยมาทั้งวันจากการไปเรียนจึงไม่ใช่ทางเลือกที่ดี [00:30]\n",
    "เคล็ดลับความสำเร็จ: ผู้พูดแชร์ประสบการณ์ส่วนตัวว่าที่ตนเองสามารถสอบติดได้นั้น เป็นเพราะการเลือกตื่นเช้ามาอ่านหนังสือ ซึ่งช่วยให้จำและทำความเข้าใจเนื้อหาได้ดีกว่ามาก [00:34]\n",
    "สรุปสั้น ๆ คือ \"หยุดนอนดึก แล้วตื่นเช้ามาอ่านหนังสือแทน\" เพื่อประสิทธิภาพสูงสุดในการเรียนครับ''']\n",
    "\n",
    "candsTemp0_0 = ['''การตื่นเช้าทำงานดีกว่าการนอนตื่นสาย การนอนหลับไม่เพียงพอทำให้ร่างกายเหนื่อยล้า\n",
    "ฮอร์โมนอะดรีนาลินช่วยกระตุ้นร่างกายให้ตื่นตัว การนอนหลับที่มีคุณภาพสำคัญต่อการฟื้นฟูร่างกาย\n",
    "การตื่นเช้าช่วยเพิ่มประสิทธิภาพในการทำงานและทำให้มีเวลามากขึ้นในการทำกิจกรรมอื่นๆ''']\n",
    "\n",
    "candsTemp0_2 = ['''ตอนที่ผมเรียนศึกษาระดับ 12 ที่โมงครับพี่ ผมตื่นตี 3 ถึง 4 น่านำให้ตื่นเช้า น้อง ๆ\n",
    "มีคนบอกเขาเป็นหมาป่ากลางคืน เป็นโดกผู้พี่จะต้องแบบ ทำงานแม่งถึงตี 2 ตี 3 ตื่นเที่ยง อ่ะ ไตสาระ\n",
    "ตื่นเช้าทำงานดีกว่าเยอะ พี่รู้จักอดิโนซีนครับ ไม่รู้ค่ะ คืออะไรฮะ เป็นศอร์โมน\n",
    "มันเหมือนศอร์โมนความเหนื่อย ตื่นมันจะเพิ่มไปเรื่อย แล้วพอนอนมันจะลง เมื่อการนักษือตอนนักคืนอ่ะ\n",
    "ศอร์โมนเครียงเนี่ยมันก็เยอะไง เราไปโรงเรียนไปมากว่า เราเหนื่อยจะตายไปแล้วอ่ะ อยู่ต้อง\n",
    "เราต้องมาต่างการนักษือกันคืนอีก ตื่นช้าหมาตินักษือ ช่วยได้เยอะมาก ผมบอกเลยว่าผมติดเค้มบี\n",
    "แล้วผมตื่นช้าหมาตินักษือ''']\n",
    "\n",
    "candsTemp0_4 = ['''การตื่นเช้ามีประโยชน์มากกว่าการนอนตื่นสาย โดยเฉพาะเมื่อพูดถึงการทำงานและการใช้ชีวิตประจำวัน\n",
    "ในคลิปวิดีโอนี้ ผู้พูดได้แบ่งปันประสบการณ์การตื่นตั้งแต่ตี 3 ถึง 4 นาฬิกา\n",
    "ซึ่งทำให้เขามีเวลาทำงานมากขึ้นในตอนกลางคืน\n",
    "การทำงานในช่วงเวลาดังกล่าวช่วยให้ผู้พูดรู้สึกสดชื่นและมีพลังมากกว่าการนอนตื่นสาย\n",
    "โดยเฉพาะอย่างยิ่งเมื่อเขาได้เรียนรู้เกี่ยวกับฮอร์โมนอาดิโนซีน\n",
    "ซึ่งเป็นฮอร์โมนที่ช่วยให้ร่างกายรู้สึกเหนื่อยล้าและทำให้ต้องการนอนหลับ\n",
    "การนอนในช่วงกลางคืนและการตื่นเช้ามีผลกระทบต่อระดับฮอร์โมนในร่างกาย\n",
    "โดยเฉพาะฮอร์โมนที่เกี่ยวข้องกับความเครียดและการพักผ่อน\n",
    "การตื่นเช้าจะช่วยให้ร่างกายได้ปรับตัวและลดความเหนื่อยล้าในระหว่างวัน  สุดท้าย\n",
    "ผู้พูดได้กล่าวถึงการทำงานในช่วงเวลาที่เหมาะสม ซึ่งทำให้เขารู้สึกมีประสิทธิภาพมากขึ้น\n",
    "และยังช่วยให้เขาไม่รู้สึกเหนื่อยล้าในระหว่างวัน''']\n",
    "\n",
    "candsTemp0_6 = ['''การทำงานในช่วงเวลาที่เหมาะสมเป็นสิ่งสำคัญที่จะช่วยให้ประสิทธิภาพในการทำงานดีขึ้น ในคลิปวิดีโอนี้\n",
    "ผู้พูดได้แบ่งปันประสบการณ์การตื่นนอนในเวลา 3:00 น. และการแนะนำให้ตื่นเช้า\n",
    "โดยมีการอธิบายถึงฮอร์โมนที่ช่วยในการทำงานและความเหนื่อยล้าที่เกิดขึ้นในช่วงเวลากลางคืน\n",
    "ผู้พูดได้เน้นย้ำว่าการตื่นเช้าและการทำงานในตอนกลางคืนนั้นดีกว่า\n",
    "และมีการกล่าวถึงการเรียนรู้ที่มากขึ้นในวันถัดไป ซึ่งทำให้รู้สึกเหนื่อยล้ามากขึ้น\n",
    "แต่การตื่นช้าก็ยังช่วยให้ลดความเครียดและเพิ่มประสิทธิภาพในการทำงานได้อย่างมาก''']\n",
    "\n",
    "cands_list = [candsTemp0_0, candsTemp0_2, candsTemp0_4, candsTemp0_6]\n",
    "\n",
    "refs_list = [refsNoteLM, refsNoteGPT, refsNotta, refsGemini]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4b0118",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"c:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbert_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m score\n\u001b[0;32m      3\u001b[0m ref \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNotebookLM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoteGPT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNotta\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGemini\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m cands_list \u001b[38;5;241m=\u001b[39m [candsTemp0_0, candsTemp0_2, candsTemp0_4, candsTemp0_6]\n",
      "File \u001b[1;32mc:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bert_score\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.12\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bert_score\\score.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxes_grid1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_axes_locatable\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n",
      "File \u001b[1;32mc:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:281\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    279\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 281\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:264\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    261\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    263\u001b[0m     )\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"c:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "ref = ['NotebookLM', 'NoteGPT', 'Notta', 'Gemini']\n",
    "\n",
    "cands_list = [candsTemp0_0, candsTemp0_2, candsTemp0_4, candsTemp0_6]\n",
    "\n",
    "refs_list = [refsNoteLM, refsNoteGPT, refsNotta, refsGemini]\n",
    "\n",
    "for j, ref in refs_list:\n",
    "    print(ref[j])\n",
    "    for i, v in enumerate(cands_list):\n",
    "        P, R, F1 = score(\n",
    "            v,\n",
    "            ref,\n",
    "            lang=\"th\",   # ภาษาไทย\n",
    "            verbose=True\n",
    "        )\n",
    "        print(\"temp = 0.\" + str(i * 2))\n",
    "        print(\"Precision:\", P.mean().item())\n",
    "        print(\"Recall:\", R.mean().item())\n",
    "        print(\"F1:\", F1.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad57b0",
   "metadata": {},
   "source": [
    "### REF = notebookLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafae1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796e9345766a473a813f60ffe1443cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f0bc70afe2475bb6dc6ebac0fee1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.15 seconds, 0.87 sentences/sec\n",
      "temp = 0.0\n",
      "Precision: 0.7759650349617004\n",
      "Recall: 0.6929143667221069\n",
      "F1: 0.7320918440818787\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb61da82bd64b0b89df1927786de32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5492357922432aa9836e891df962c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.59 seconds, 1.69 sentences/sec\n",
      "temp = 0.2\n",
      "Precision: 0.6901212930679321\n",
      "Recall: 0.6808103919029236\n",
      "F1: 0.6854342818260193\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a64a02f92ce44dc9f2d508d409c80a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5885a6d50dc1475888917026929ebc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.64 seconds, 1.56 sentences/sec\n",
      "temp = 0.4\n",
      "Precision: 0.772847056388855\n",
      "Recall: 0.7457031607627869\n",
      "F1: 0.7590325474739075\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1043bd13134f4e3abb27b46d184a974c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89d0c79209741ee82a11346a5bbb7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.56 seconds, 1.78 sentences/sec\n",
      "temp = 0.6\n",
      "Precision: 0.7707051038742065\n",
      "Recall: 0.7215945720672607\n",
      "F1: 0.7453417181968689\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "for i, v in enumerate(cands_list):\n",
    "    P, R, F1 = score(\n",
    "        v,\n",
    "        refsNoteLM,\n",
    "        lang=\"th\",   # ภาษาไทย\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"temp = 0.\" + str(i * 2))\n",
    "    print(\"Precision:\", P.mean().item())\n",
    "    print(\"Recall:\", R.mean().item())\n",
    "    print(\"F1:\", F1.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105eff2d",
   "metadata": {},
   "source": [
    "แม้ไม่มีคำซ้ำกันเลย แต่ semantic representation ของประโยคใกล้กันมาก (~73%)\n",
    "Precision ≈ Recall ≈ 0.73 ตีความว่า:\n",
    "-ไม่ได้แต่งข้อมูลเพิ่ม\n",
    "-ไม่ได้ตัดสาระสำคัญทิ้ง"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa5115",
   "metadata": {},
   "source": [
    "### REF = noteGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74afbef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266345f8320c46698e6a004d53494625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb71885223ef45d595b64c1c8e2fc6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.47 seconds, 2.12 sentences/sec\n",
      "temp = 0.0\n",
      "Precision: 0.7594972848892212\n",
      "Recall: 0.7152698040008545\n",
      "F1: 0.7367203831672668\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778b8cdb31514033bb04c7ee62064bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c218c064b7df4a71a10da3b199f81b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.54 seconds, 1.85 sentences/sec\n",
      "temp = 0.2\n",
      "Precision: 0.6682387590408325\n",
      "Recall: 0.6718220710754395\n",
      "F1: 0.6700255870819092\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c64a9caa958460faba5a4ff3b9705d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f210823cd3c84b9685d0bb9a8294b650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.72 seconds, 1.40 sentences/sec\n",
      "temp = 0.4\n",
      "Precision: 0.7514249682426453\n",
      "Recall: 0.7700244188308716\n",
      "F1: 0.7606109976768494\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f771bf325242e195622bb4352c288b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b227e3db313e435e9b99e7f6815bd506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.49 seconds, 2.04 sentences/sec\n",
      "temp = 0.6\n",
      "Precision: 0.782317042350769\n",
      "Recall: 0.771477460861206\n",
      "F1: 0.7768594026565552\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "for i, v in enumerate(cands_list):\n",
    "    P, R, F1 = score(\n",
    "        v,\n",
    "        refsNoteGPT,\n",
    "        lang=\"th\",   # ภาษาไทย\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"temp = 0.\" + str(i * 2))\n",
    "    print(\"Precision:\", P.mean().item())\n",
    "    print(\"Recall:\", R.mean().item())\n",
    "    print(\"F1:\", F1.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08794d93",
   "metadata": {},
   "source": [
    "### REF = notta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f483bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b881871db24caf922b924c45fe8fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04758132149044b586c859ef38d42159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.71 seconds, 1.40 sentences/sec\n",
      "temp = 0.0\n",
      "Precision: 0.7387385368347168\n",
      "Recall: 0.6770601272583008\n",
      "F1: 0.7065558433532715\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51f90b7b1ed4c9c865ed2f7888e203b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79027b6126f64c36b48998ebceef3a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.64 seconds, 1.56 sentences/sec\n",
      "temp = 0.2\n",
      "Precision: 0.7124986052513123\n",
      "Recall: 0.6958467960357666\n",
      "F1: 0.7040742635726929\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ab16672d1e45fa9310861f5f968125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09dead5e599c4fc69ecd5c4c66a78eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.64 seconds, 1.57 sentences/sec\n",
      "temp = 0.4\n",
      "Precision: 0.7695484757423401\n",
      "Recall: 0.7622040510177612\n",
      "F1: 0.7658586502075195\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7145373d34c54ff298efd0516259e7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b22bf0a24e4c91b86ec95b36a226d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.65 seconds, 1.53 sentences/sec\n",
      "temp = 0.6\n",
      "Precision: 0.7898309826850891\n",
      "Recall: 0.7514249086380005\n",
      "F1: 0.7701493501663208\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "for i, v in enumerate(cands_list):\n",
    "    P, R, F1 = score(\n",
    "        v,\n",
    "        refsNotta,\n",
    "        lang=\"th\",   # ภาษาไทย\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"temp = 0.\" + str(i * 2))\n",
    "    print(\"Precision:\", P.mean().item())\n",
    "    print(\"Recall:\", R.mean().item())\n",
    "    print(\"F1:\", F1.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1493f",
   "metadata": {},
   "source": [
    "### REF = gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b0ebcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"c:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbert_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cands_list):\n\u001b[0;32m      4\u001b[0m     P, R, F1 \u001b[38;5;241m=\u001b[39m score(\n\u001b[0;32m      5\u001b[0m         v,\n\u001b[0;32m      6\u001b[0m         refsGemini,\n\u001b[0;32m      7\u001b[0m         lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# ภาษาไทย\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bert_score\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.12\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bert_score\\score.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxes_grid1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_axes_locatable\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n",
      "File \u001b[1;32mc:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:281\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    279\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 281\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:264\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    261\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    263\u001b[0m     )\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"c:\\Users\\North\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "for i, v in enumerate(cands_list):\n",
    "    P, R, F1 = score(\n",
    "        v,\n",
    "        refsGemini,\n",
    "        lang=\"th\",   # ภาษาไทย\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"temp = 0.\" + str(i * 2))\n",
    "    print(\"Precision:\", P.mean().item())\n",
    "    print(\"Recall:\", R.mean().item())\n",
    "    print(\"F1:\", F1.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26352c",
   "metadata": {},
   "source": [
    "# BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed974ca",
   "metadata": {},
   "source": [
    "### สรุป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a6af16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sacrebleu import corpus_bleu\n",
    "\n",
    "# ผลลัพธ์ที่โมเดลสร้าง (candidate)\n",
    "cands  = ['''การตื่นเช้าทำงานดีกว่าการนอนตื่นสาย การนอนหลับไม่เพียงพอทำให้ร่างกายเหนื่อยล้า\n",
    "ฮอร์โมนอะดรีนาลินช่วยกระตุ้นร่างกายให้ตื่นตัว การนอนหลับที่มีคุณภาพสำคัญต่อการฟื้นฟูร่างกาย\n",
    "การตื่นเช้าช่วยเพิ่มประสิทธิภาพในการทำงานและทำให้มีเวลามากขึ้นในการทำกิจกรรมอื่นๆ''']\n",
    "\n",
    "# คำตอบอ้างอิง (reference) — ต้องเป็น list of lists\n",
    "refs = [\"เนื้อหาจากแหล่งข้อมูลนี้เน้นย้ำถึง ความสำคัญของการตื่นเช้า เพื่อเพิ่มประสิทธิภาพในการเรียนและการทำงานให้สูงสุด ผู้พูดได้โต้แย้งความเชื่อเรื่องการเป็นคนถนัดทำงานกลางคืน โดยชี้ให้เห็นว่า การสะสมของฮอร์โมนความเหนื่อยล้า ตลอดทั้งวันจะทำให้การอ่านหนังสือในช่วงดึกไม่มีคุณภาพเท่าที่ควร การปรับเปลี่ยนพฤติกรรมมา ตื่นนอนในช่วงเช้ามืด เช่น เวลาตีสามหรือตีสี่ จะช่วยให้ร่างกายมีความพร้อมและมีสมาธิในการรับข้อมูลใหม่ได้ดีกว่า การมีวินัยในกิจวัตรยามเช้าถูกนำเสนอว่าเป็น กุญแจสำคัญสู่ความสำเร็จ ทางการศึกษา ดังเช่นประสบการณ์ตรงของผู้พูดที่สามารถสอบติดคณะแพทยศาสตร์ได้ ผลลัพธ์ที่ได้จากการทำงานอย่างมีคุณภาพในช่วงเช้าจึง มีค่ามากกว่าการฝืนอ่านหนังสือ ในขณะที่ร่างกายอ่อนล้าอย่างเทียบไม่ได้\"]\n",
    "\n",
    "bleu = corpus_bleu(cands, refs)\n",
    "\n",
    "print(\"BLEU score:\", bleu.score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86e1ad",
   "metadata": {},
   "source": [
    "BLEU มันเทียบความเหมือนของ cand, ref ผมเลยเอามาใช้กับ speech to text แทนการทดสอบสรุป เพราะ speech to text มันมี ref ที่ชัดเจน แต่สรุปเราไม่มี ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8671b",
   "metadata": {},
   "source": [
    "### Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd54d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [\n",
    "    [\"ผมทำงานแบบคุณภาพตื่นเช้าครับตอนที่ผม อ่านหนังสือ 12 ชม.ครับพี่ผมตื่น 3:00 นึง 4:00 น.แนะนำให้ตื่นเช้าน้องๆบางคน บอกเ้าเนี่ยเป็นหมาป่ากลางคืนเป็นรกคู่ ที่จะต้องแบบทำงานถึง 2:00 น. 3:00 น.ตื่นเที่ยงอะไร >> อ่า >> ไร้สาระ >> อ่า >> ตื่นเช้าทำงานดีกว่าเยอะพี่รู้จักซีนป่ะ ครับ >> ไม่รู้ฮะคืออะไรฮะเป็นฮอร์โมนมันเหมือน ฮอร์โมนความเหนื่อยตื่นมันจะเพิ่มเรื่อยๆ แล้วพอนอนปุ๊บมันจะลง >> มึงอ่านหนังสือตอนกลางคืนน่ะฮอร์โมน เนี่ยมันก็เยอะไง >> เราไปโรงเรียนไปทั้งวันเราเราเหนื่อยตาย อยู่แล้วอ่ะ >> ถูกต้อง >> เราจะต้องมานั่งอ่านหนังสือกลางคืนอีก [เพลง]ตื่นเช้ามาอ่านหนังสือถ้วยได้เยอะ มากผมบอกเลยว่าผมติดเค็มเพราะผมตื่นเช้า อ่านหนังสือ Ja.\"]\n",
    "]\n",
    "candidates_temp0_0 = [\n",
    "    \"ทำงานแบบคุณภาพ ตื่นเช้าครับตอนที่ผมอ่านศึกษือ 12 ที่โมงครับพี่ผมตื่นตี 3 ถึง 4 น่านำให้ตื่นเช้าน้อง ๆ มีคนบอกเขาเป็นหมาป่ากลางคืนเป็นโดกผู้พี่จะต้องแบบทำงานแม่งถึงตี 2 ตี 3 ตื่นเที่ยงอ่า...ไตสาระตื่นเช้าทำงานดีกว่าเยอะพี่รู้จักอดิโนซีนครับไม่รู้ว่าคืออะไรฮะเป็นศอร์โมนมันเหมือนศอร์โมนความเหนื่อยตื่นมันจะเพิ่มไปเรื่อยแล้วพอนอนมันจะลงเมื่อการนักษือตอนนักคืนอ่ะศอร์โมนเครียงเนี่ยมันก็เยอะไงเราไปโรงเรียนไปมากว่าเราเหนื่อยตายไปแล้วอ่ะอยู่ต้องเราต้องมาต่างการนักษือกันมาคืนอีกตื่นช้าหมาตนักษือช่วยได้เยอะมากผมบอกเลยว่าผมติดเคมีดาว่าผมตื่นช้าหมาตนักษือ\"\n",
    "]\n",
    "candidates_temp0_2 = [\n",
    "    \"ผมทำงานแบบคุณภาพ ตื่นเช้าครับตอนที่ผมอ่านศึกษือ 12 ที่โมงครับพี่ผมตื่นตี 3 ถึง 4 น่านำให้ตื่นเช้าน้อง ๆ มีคนบอกเขาเป็นหมาป่ากลางคืนเป็นโดกผู้พี่จะต้องแบบทำงานแม่งถึงตี 2 ตี 3 ตื่นเที่ยงอ่ะไตสาระตื่นเช้าทำงานดีกว่าเยอะพี่รู้จักอดิโนซีนครับไม่รู้ค่ะ คืออะไรฮะเป็นศอร์โมนมันเหมือนศอร์โมนความเหนื่อยตื่นมันจะเพิ่มไปเรื่อยแล้วพอนอนมันจะลงเมื่อการนักษือตอนนักคืนอ่ะศอร์โมนเครียงเนี่ยมันก็เยอะไงเราไปโรงเรียนไปมากว่าเราเหนื่อยจะตายไปแล้วอ่ะอยู่ต้องเราต้องมาต่างการนักษือกันคืนอีกตื่นช้าหมาตินักษือช่วยได้เยอะมากผมบอกเลยว่าผมติดเค้มบีแล้วผมตื่นช้าหมาตินักษือ\"\n",
    "]\n",
    "candidates_temp0_4 = [\n",
    "    \"ทำงานแบบคุณอภาพ ตื่นเช้าครับตอนที่ผมอ่านศึง 12 ที่โมงครับพี่ผมตื่นตี 3 ถึง 4 น่านำให้ตื่นเช้าน้อง ๆ คนบอก เขาเป็นหมาป่า กลางคืนเป็นโดกผู้พี่จะต้องแบบทำงานแม่งถึงตี 2 ตี 3 ตื่นเที่ยงไต้สาระตื่นเช้าทำงานดีกว่าเยอะพี่รู้จักอาดิโนซีนครับไม่รู้ว่าคืออะไรครับเป็นฮอร์โมน มันเหมือนฮอร์โมนความเหนื่อยตื่นมันจะเพื่อไปเรื่อยแล้วพอนอน มันจะลงมึงกับนักษิตอนนักคืน ฮอร์โมนเครียงเนี่ยมันก็เยอะไงเราไปโลกเรียนไปมาก ว่าเราเหนื่อยจะตายไปแล้วอยู่ต้องเราต้องมาต่างการนักษิกับมาคืนอีกตื่นเช้าผ่านนักษิ ช่วยได้เยอะมากผมบอกเลยว่าผมติดเค้มอีกว่าผมตื่นเช้ามาก\"\n",
    "]\n",
    "candidates_temp0_6 = [\n",
    "    \"ไปทำงานแบบคุณอภาพ ตื่นเช้าครับตอนที่ผมอ่านตั้งสือ 12 ชมงต์มวงครับพี่ผมตื่น ตี 3 จิมตี 4แนะนำให้ตื่นเช้าน้องๆ มีคนบอกเขาเนี่ยเป็นหมาป่ากลางคืนเป็นโลกฮู่พี่ นี่ต้องแบบทำงานแม่งถึง ตี 2 ตี 3 ตื่นเที่ยงไปสาระตื่นเช้าทำงานดีกว่าเยอะพี่รู้จักอดิโนซีลครับไม่รู้ค่ะ คืออะไรฮะเป็นฮอร์โมน มันเหมือนฮอร์โมนความเหนื่อยสื่อมันจะเพิ่มไม่เหลือย แล้วพอนอนปื้นมันจะลงเมื่องานศึกตอนนักคืน ฮอร์โมนเครียงนี่มันก็เยอะไงเราไปโลกเรียนไปมากวัน เราเหนื่อยตายแล้วถูกต้องเราป้องมานั่นการศึกลับคืนอีก ตื่นช้ามาตรงสื่อช่วยได้เยอะมากผมบอกเลยว่าผมติดเคมีในติดซ้อมาสิ\"\n",
    "]\n",
    "transcript_list = [candidates_temp0_0, candidates_temp0_2, candidates_temp0_4, candidates_temp0_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9fa2b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score(temp = 0.0): 0.0\n",
      "BLEU score(temp = 0.2): 0.6274493484036631\n",
      "BLEU score(temp = 0.4): 0.17325410659206988\n",
      "BLEU score(temp = 0.6): 0.5229703758249408\n"
     ]
    }
   ],
   "source": [
    "from sacrebleu import corpus_bleu\n",
    "\n",
    "for i, v in enumerate(cands_list):\n",
    "    bleu = corpus_bleu(v, references)\n",
    "    print(f\"BLEU score(temp = 0.{i*2}):\", bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e37bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BERTScore Evaluation Script\n",
      "============================================================\n",
      "\n",
      "🔄 Refreshing token...\n",
      "🔄 Token refreshed successfully\n",
      "\n",
      "========================================\n",
      "Processing: https://www.youtube.com/shorts/Mr0Fce0E7TQ\n",
      "========================================\n",
      "  Calling API with temp=0.0...\n",
      "  Waiting for job 09db4609-87ff-4f6d-a118-99d9556c0b05...\n",
      "  temp 0.0: 244 chars\n",
      "  Calling API with temp=0.2...\n",
      "  Waiting for job d9e57074-d88d-480e-a21a-945e11d5e0db...\n",
      "Error checking status: Job failed with status: ERROR\n",
      "Error checking status: Job failed with status: ERROR\n",
      "  temp 0.2: 390 chars\n",
      "  Calling API with temp=0.4...\n",
      "  Waiting for job ecd8cef5-4cae-4508-8628-f2741c1e2855...\n",
      "  temp 0.4: 424 chars\n",
      "  Calling API with temp=0.6...\n",
      "🔄 Token refreshed successfully\n",
      "  Waiting for job 11df7a6e-3a06-448a-aeaa-4ab29ee5571c...\n",
      "Error checking status: Job failed with status: ERROR\n",
      "Error checking status: Job failed with status: ERROR\n",
      "  temp 0.6: 752 chars\n",
      "\n",
      "========================================\n",
      "Processing: https://www.youtube.com/shorts/IQTOZZRi1qY\n",
      "========================================\n",
      "  Calling API with temp=0.0...\n",
      "  Waiting for job 734b427c-1dce-464e-a537-a9365a8c6a8e...\n",
      "  temp 0.0: 259 chars\n",
      "  Calling API with temp=0.2...\n",
      "  Waiting for job c7d1ca33-2070-4162-80e6-131a90be3c6c...\n",
      "  temp 0.2: 346 chars\n",
      "  Calling API with temp=0.4...\n",
      "  Waiting for job e5d9f3b5-f893-4c38-927b-8f346eafa593...\n",
      "  temp 0.4: 358 chars\n",
      "  Calling API with temp=0.6...\n",
      "  Waiting for job 9511f79f-d86c-4e72-92fb-f06754097335...\n",
      "  temp 0.6: 315 chars\n",
      "\n",
      "============================================================\n",
      "Calculating BERTScore...\n",
      "============================================================\n",
      "  Skipping Notta for https://www.youtube.com/shorts/Mr0Fce0E7TQ - no reference\n",
      "  Skipping ChatGPT for https://www.youtube.com/shorts/Mr0Fce0E7TQ - no reference\n",
      "  Skipping Gemini for https://www.youtube.com/shorts/Mr0Fce0E7TQ - no reference\n",
      "  Skipping Notta for https://www.youtube.com/shorts/IQTOZZRi1qY - no reference\n",
      "  Skipping ChatGPT for https://www.youtube.com/shorts/IQTOZZRi1qY - no reference\n",
      "  Skipping Gemini for https://www.youtube.com/shorts/IQTOZZRi1qY - no reference\n",
      "\n",
      "============================================================\n",
      "Saving to Excel...\n",
      "============================================================\n",
      "\n",
      "✅ Results saved to: evaluation_results_20260115_040144.xlsx\n",
      "   - Sheet 'BERTScore': รายละเอียดทุก comparison\n",
      "   - Sheet 'Summaries': ข้อความสรุปทั้งหมด\n",
      "   - Sheet 'Summary by Video': สรุปแยกตามวิดีโอ\n",
      "   - Sheet 'Average by Temp': ค่าเฉลี่ยแยกตาม temp\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BERTScore Evaluation Script\n",
    "เปรียบเทียบสรุปจากระบบ (whisper_temp ต่างๆ) กับ reference tools\n",
    "\n",
    "วิธีใช้:\n",
    "1. ใส่ YouTube links ใน YOUTUBE_LINKS\n",
    "2. ใส่ reference summaries ใน REFERENCE_SUMMARIES\n",
    "3. ใส่ REFRESH_TOKEN\n",
    "4. รัน script\n",
    "5. ผลลัพธ์จะ save ใน evaluation_results.xlsx\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from bert_score import score\n",
    "from datetime import datetime\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "API_BASE = \"http://localhost:8081\"\n",
    "AUTH_BASE = \"http://localhost:4005\"\n",
    "WHISPER_TEMPS = [0.0, 0.2, 0.4, 0.6]\n",
    "REF_TOOLS = ['Notta', 'ChatGPT', 'Gemini']\n",
    "\n",
    "# ⚠️ ใส่ refresh token ที่นี่\n",
    "REFRESH_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOjIsImlhdCI6MTc2ODIxMTQzMSwiZXhwIjoxNzY4ODE2MjMxfQ.fTULfpbcAa52afFiZ4CLUoDasTMO5IRUHihSFe0ElSM\"\n",
    "\n",
    "# Access token (จะ refresh อัตโนมัติ)\n",
    "ACCESS_TOKEN = \"\"\n",
    "\n",
    "# ใส่ YouTube links ที่ต้องการทดสอบ\n",
    "YOUTUBE_LINKS = [\n",
    "    \"https://www.youtube.com/shorts/Mr0Fce0E7TQ\",\n",
    "    \"https://www.youtube.com/shorts/IQTOZZRi1qY\",\n",
    "    # เพิ่มได้ตามต้องการ\n",
    "]\n",
    "\n",
    "# ใส่ reference summaries แบบ manual\n",
    "# Format: { \"VIDEO_ID\": { \"tool_name\": \"summary text\" } }\n",
    "REFERENCE_SUMMARIES = {\n",
    "    \"Mr0Fce0E7TQ\": {\n",
    "        \"Notta\": '''การสนทนานี้เป็นการสาธิตวิธีการวัดความยาวรอบเอวโดยไม่ใช้สายวัด โดยใช้หลักการทางฟิสิกส์ของลูกตุ้มแทน ผู้พูดหลักได้อธิบายขั้นตอนการทำงานอย่างละเอียด\n",
    "\n",
    "ในขั้นตอนแรก ผู้พูดได้ขอให้เอาเชือกมาใช้ในการวัดรอบเอว และให้ตัดเชือกให้มีความยาวเท่ากับรอบเอวที่ต้องการวัด ผู้พูดได้กล่าวถึงการใช้เชือกนี้เป็นเครื่องมือหลักในการวัด\n",
    "\n",
    "ขั้นตอนที่สองที่ผู้พูดอธิบายคือการนำเชือกที่ได้มาผูกกับวัตถุใดๆ เพื่อทำเป็นลูกตุ้ม จากนั้นให้จับเวลาการแกว่งของลูกตุ้มนี้เป็นจำนวน 10 ครั้ง ผู้พูดได้ทำการทดลองและได้ผลลัพธ์ว่าการแกว่ง 10 ครั้งใช้เวลา 18.24 วินาที ดังนั้นการแกว่ง 1 ครั้งจึงใช้เวลา 1.824 วินาที\n",
    "\n",
    "ในขั้นตอนสุดท้าย ผู้พูดได้นำข้อมูลที่ได้มาใส่ในสูตรฟิสิกส์ T = 2π√L/g โดยที่ T คือคาบการแกว่ง L คือความยาวของเชือก และ g คือค่าความเร่งโน้มถ่วง 9.8 เมตรต่อวินาทีกำลังสอง ผู้พูดได้คำนวณและได้ผลลัพธ์ว่าความยาวของเชือกประมาณ 32 นิ้ว ซึ่งหมายความว่ารอบเอวมีขนาด 32 นิ้ว''',\n",
    "        \"ChatGPT\": '''สรุป **คลิป YouTube Shorts นี้** (จากลิงก์ที่คุณส่ง):\n",
    "👉 วิดีโอนั้นเป็นคลิปสั้นเกี่ยวกับ *วิธีวัดรอบเอวโดยไม่ต้องใช้สายวัด* โดยผู้สร้างคลิปใช้วิธีง่าย ๆ ที่สามารถทำได้ด้วยตัวเองหรืออุปกรณ์พื้นฐานในชีวิตประจำวัน 👇 ([YouTube][1])\n",
    "\n",
    "### 🧠 ประเด็นหลัก (สรุปตรง ๆ)\n",
    "\n",
    "* แสดง *วิธีวัดรอบเอว* แบบไม่ใช้อุปกรณ์วัดแบบทางการ (เช่นสายวัด)\n",
    "* ใช้วิธีประยุกต์ที่เข้าใจง่ายและทำได้ทันที\n",
    "* คลิปเป็นรูปแบบ *YouTube Shorts* (วิดีโอแนวตั้งสั้น ๆ) ความยาวไม่เกิน 60 วินาที ([YouTube][1])\n",
    "\n",
    "### 📌 สรุปสั้น\n",
    "\n",
    "เนื้อหาคลิป: **แนวทางวัดรอบเอวแบบไม่ต้องใช้สายวัด** — เหมาะสำหรับใครที่อยากทราบขนาดตัวแบบง่าย ๆ โดยไม่ต้องมีเครื่องมือเฉพาะ ([YouTube][1])\n",
    "\n",
    "ถ้าคุณอยากให้สรุป *แบบละเอียดตามช่วงเวลาในวิดีโอ* หรือแปลความหมายขององค์ประกอบบางส่วนของคลิป (เช่น เทคนิคหรือคำอธิบายแบบ step-by-step) บอกฉันได้เลย!\n",
    "\n",
    "[1]: https://www.youtube.com/shorts/Mr0Fce0E7TQ?utm_source=chatgpt.com \"Measuring waist circumference without a measuring tape ...\"\n",
    "''',\n",
    "        \"Gemini\": '''จากวิดีโอ **\"วัดความยาวรอบเอวโดยไม่ใช้สายวัด\"** ของช่อง **Mr.Phoops** สามารถสรุปวิธีการวัดรอบเอวด้วยหลักฟิสิกส์ง่ายๆ ดังนี้ครับ:\n",
    "\n",
    "**หลักการ:** ใช้เชือกวัดรอบเอว แล้วนำเชือกนั้นมาทำเป็นลูกตุ้มนาฬิกา (Simple Pendulum) เพื่อคำนวณหาความยาวเชือกจากคาบการแกว่ง\n",
    "\n",
    "**ขั้นตอนการทำ:**\n",
    "\n",
    "1. **วัดรอบเอว:** เอาเชือกมาพันรอบเอวเพื่อให้ได้ความยาวที่ต้องการ แล้วตัดเชือก [[00:00](http://www.youtube.com/watch?v=Mr0Fce0E7TQ&t=0)]\n",
    "2. **ทำลูกตุ้ม:** นำเชือกเส้นนั้นมาผูกกับวัตถุอะไรก็ได้ให้มีน้ำหนักถ่วงเป็นลูกตุ้ม [[00:11](http://www.youtube.com/watch?v=Mr0Fce0E7TQ&t=11)]\n",
    "3. **จับเวลา:** แกว่งเชือกและจับเวลาการแกว่งครบ 10 รอบ (ในคลิปได้เวลา 18.24 วินาที) [[00:14](http://www.youtube.com/watch?v=Mr0Fce0E7TQ&t=14)]\n",
    "4. **คำนวณ:**\n",
    "* หาเวลาต่อ 1 รอบ (คาบ ) =  วินาที\n",
    "* ใช้สูตรฟิสิกส์  (โดย  คือความยาวเชือก, )\n",
    "* ย้ายข้างสมการเพื่อหา  จะได้  [[00:26](http://www.youtube.com/watch?v=Mr0Fce0E7TQ&t=26)]\n",
    "\n",
    "\n",
    "\n",
    "**สรุปผล:**\n",
    "จากการคำนวณในคลิป ได้ความยาวรอบเอวประมาณ **32 นิ้ว** ครับ [[00:35](http://www.youtube.com/watch?v=Mr0Fce0E7TQ&t=35)]''',\n",
    "    },\n",
    "    \"IQTOZZRi1qY\": {\n",
    "        \"Notta\": '''การสนทนานี้เป็นการพูดคุยเกี่ยวกับความสัมพันธ์และความเข้ากันได้ระหว่างบุคคล โดยมีการหยิบยกประเด็นต่างๆ เกี่ยวกับลักษณะนิสัยและความชอบของแต่ละคน ผู้พูดได้แสดงความคิดเห็นเกี่ยวกับการมีเพื่อนสนิทเป็นผู้ชายและการใช้เวลาร่วมกัน\n",
    "\n",
    "ในช่วงแรกของการสนทนา ผู้พูดได้กล่าวถึงความชอบคนที่มีลักษณะขี้อ้อนและชอบเที่ยวกลางคืน โดยแสดงความยินดีที่จะไปเที่ยวด้วยกัน แต่ไม่ชอบการไปคนเดียวบ่อยๆ ผู้พูดยังได้กล่าวถึงเรื่องเพื่อนสนิทเป็นผู้ชายที่ไปด้วยกันตลอดและกินข้าวด้วยกันสองคน ซึ่งผู้พูดแสดงความไม่พอใจและยอมรับว่าตนเองใจแคบ\n",
    "\n",
    "การสนทนาได้หันไปพูดถึงนิสัยการอ่านหนังสือและการเช็คโทรศัพท์ ผู้พูดแสดงความไม่ชอบการอ่านหนังสือและมีนิสัยเช็คโทรศัพท์บ่อย ซึ่งถูกมองว่าเป็นสัญญาณของการไม่ไว้ใจกัน\n",
    "\n",
    "ประเด็นเรื่องการมีลูกก็ถูกหยิบยกขึ้นมา โดยผู้พูดแสดงความไม่อยากมีลูก แต่แสดงความชอบลูกครึ่งไทย-จีน การศึกษาต่อต่างประเทศก็เป็นอีกหัวข้อหนึ่ง ผู้พูดสามารถพูดภาษาอังกฤษได้พอสมควรและสนใจเรียนต่อที่อเมริกา\n",
    "\n",
    "เรื่องงานการงานเป็นประเด็นที่ผู้พูดแสดงความกระตือรือร้น โดยชอบงานหนักและอธิบายตนเองว่าเป็นคนบ้างาน ความชอบในเรื่องอาหารก็ถูกกล่าวถึง โดยเฉพาะอาหารอีสานที่ผู้พูดแสดงความชอบมาก\n",
    "\n",
    "ท้ายสุดของการสนทนา มีการกล่าวถึง \"CK Fast Money\" ซึ่งดูเหมือนจะเป็นการอ้างอิงถึงบุคคลหรือสิ่งใดสิ่งหนึ่งที่เกี่ยวข้องกับการสนทนา''',\n",
    "        \"ChatGPT\": '''## 📌 สรุปคลิป (บทสนทนาแนวขำ ๆ / Speed Dating)\n",
    "\n",
    "คลิปนี้เป็น **บทสนทนาเชิงล้อเลียนการคุยเลือกคู่** ไล่เช็ก “เงื่อนไขความเข้ากันได้” แบบเร็ว ๆ ตั้งแต่เรื่องนิสัย ความหึง ไลฟ์สไตล์ ไปจนถึงอนาคตชีวิต แล้วจบด้วย **พล็อตหักมุม** ที่เฉลยว่าคู่ที่ได้ไม่ใช่คน แต่เป็นแบรนด์ **CK Fast** ทำให้ทั้งหมดกลายเป็นมุกโฆษณา/มุกตลก\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 วิเคราะห์เนื้อหา (สั้นแต่ลึก)\n",
    "\n",
    "* **โทน**: ตลก ปั่น ๆ ใช้ภาษาพูดแรง ๆ เพื่อเรียกเสียงหัวเราะ\n",
    "* **โครงเรื่อง**: ถาม–ตอบเร็ว → ผ่าน/ไม่ผ่าน → สร้างความคาดหวัง → เฉลยหักมุม\n",
    "* **ธีมหลัก**:\n",
    "\n",
    "  * ความขี้อ้อน / ความหึง / ความไว้ใจ\n",
    "  * เที่ยวกลางคืน–เพื่อนสนิทเพศตรงข้าม\n",
    "  * ไม่อยากมีลูก / ลูกครึ่ง / เรียนนอก\n",
    "  * บ้างาน / ไลฟ์สไตล์การกิน\n",
    "* **จุดขาย**: ทุกอย่าง “โอเคได้” จนเจอเส้นแดง (หึงแรง ไม่ชอบเพื่อนสนิทเพศตรงข้าม) แล้วสุดท้ายเฉลยเป็นมุกแบรนด์\n",
    "\n",
    "---\n",
    "\n",
    "## 🧾 สรุปย่อ (Bullet)\n",
    "\n",
    "* คุยเช็กสเปกแบบขำ ๆ ผ่านหลายเงื่อนไข\n",
    "* บางข้อรับได้ บางข้อไม่ผ่าน (หึง/ความไว้ใจ)\n",
    "* บทสนทนาทำให้คนดูคิดว่าเลือกคู่คนจริง\n",
    "* **เฉลยหักมุม**: คู่คือ **CK Fast** → ตลก/โฆษณาแฝง\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 ตัวอย่างสรุปสั้นมาก (1 ประโยค)\n",
    "\n",
    "> “คลิปบทสนทนาตลกแนวเลือกคู่ ไล่เช็กนิสัยและไลฟ์สไตล์ ก่อนหักมุมเฉลยว่าคู่ที่ได้คือแบรนด์ CK Fast”\n",
    "\n",
    "ถ้าต้องการ **สรุปแบบอินโฟกราฟิก**, **แยกมุก–สาระ**, หรือ **เขียนสคริปต์เลียนแบบสไตล์นี้** บอกได้เลย เดี๋ยวจัดให้ครับ 😄\n",
    "''',\n",
    "        \"Gemini\": '''วิดีโอนี้เป็นชาเลนจ์สนุกๆ ชื่อ \"ไปต่อหรือพอแค่นี้\" ที่ทำโดยคุณ Mr.Phoops (พี่ภูผา) โดยมีเนื้อหาเกี่ยวกับการเลือกสเปคหรือลักษณะนิสัยของคนที่คบหาด้วยว่าเขาจะยอมรับได้หรือไม่:\n",
    "\n",
    "ขี้อ้อน: ไปต่อ (ชอบคนขี้อ้อน) [00:00]\n",
    "\n",
    "ชอบเที่ยวกลางคืน: ไปต่อ (ถ้าไปด้วยกันได้ แต่ถ้าไปคนเดียวบ่อยๆ ไม่ไหว) [00:04]\n",
    "\n",
    "มีเพื่อนสนิทเพศตรงข้าม: พอแค่นี้ (ถ้าสนิทแบบไปไหนมาไหนสองคนตลอด รับไม่ได้) [00:12]\n",
    "\n",
    "ไม่ชอบอ่านหนังสือ: พอแค่นี้ (บอกให้กลับไปอ่านหนังสือซะ) [00:15]\n",
    "\n",
    "เช็คโทรศัพท์: พอแค่นี้ (มองว่าถ้าเช็คบ่อยแปลว่าไม่ไว้ใจกัน) [00:19]\n",
    "\n",
    "ไม่อยากมีลูก: ไปต่อ (พี่ภูผาก็ไม่อยากมีลูกเหมือนกัน) [00:24]\n",
    "\n",
    "ลูกครึ่งไทยจีน/นักเรียนนอก: ไปต่อ (ชอบลูกครึ่ง รับได้หมด) [00:28]\n",
    "\n",
    "บ้างาน: ไปต่อ (ชอบ เพราะตัวเองก็บ้างานเหมือนกัน) [00:37]\n",
    "\n",
    "ชอบกินอาหารอีสาน: ไปต่อ (ชอบมาก กินทั้งวันก็ได้) [00:42]\n",
    "\n",
    "บทสรุปตอนท้าย: ผลลัพธ์คู่ของคุณ Mr.Phoops ที่ได้ออกมาคือ CK Fastwork ซึ่งทำให้เขาตกใจและสบถออกมาอย่างฮาๆ [00:50]''',\n",
    "    },\n",
    "    # เพิ่มได้ตามต้องการ\n",
    "}\n",
    "\n",
    "# ================== AUTH FUNCTIONS ==================\n",
    "\n",
    "def refresh_access_token():\n",
    "    \"\"\"ดึง access token ใหม่จาก refresh token\"\"\"\n",
    "    global ACCESS_TOKEN\n",
    "    \n",
    "    if not REFRESH_TOKEN or REFRESH_TOKEN == \"YOUR_REFRESH_TOKEN_HERE\":\n",
    "        print(\"⚠️ No REFRESH_TOKEN set, cannot refresh\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            f\"{AUTH_BASE}/auth/refresh\",\n",
    "            cookies={\"refresh_token\": REFRESH_TOKEN}\n",
    "        )\n",
    "        \n",
    "        if resp.status_code == 200 or resp.status_code == 201:\n",
    "            ACCESS_TOKEN = resp.cookies.get(\"access_token\", \"\")\n",
    "            if not ACCESS_TOKEN:\n",
    "                data = resp.json()\n",
    "                ACCESS_TOKEN = data.get(\"accessToken\") or data.get(\"access_token\", \"\")\n",
    "            print(f\"🔄 Token refreshed successfully\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Refresh failed: {resp.status_code} - {resp.text}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Refresh error: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_headers():\n",
    "    \"\"\"สร้าง headers พร้อม token\"\"\"\n",
    "    if ACCESS_TOKEN:\n",
    "        return {\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"}\n",
    "    return {}\n",
    "\n",
    "# ================== HELPER FUNCTIONS ==================\n",
    "\n",
    "def extract_video_id(url: str) -> str:\n",
    "    \"\"\"ดึง video ID จาก YouTube URL\"\"\"\n",
    "    if \"v=\" in url:\n",
    "        return url.split(\"v=\")[1].split(\"&\")[0]\n",
    "    elif \"youtu.be/\" in url:\n",
    "        return url.split(\"youtu.be/\")[1].split(\"?\")[0]\n",
    "    return url\n",
    "\n",
    "def wait_for_summary(job_id: str, timeout: int = 3000) -> dict:\n",
    "    \"\"\"รอจน summarization เสร็จ\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        try:\n",
    "            response = requests.get(f\"{API_BASE}/summary/{job_id}\", headers=get_headers())\n",
    "            \n",
    "            # ถ้า 401 ลอง refresh token\n",
    "            if response.status_code == 401:\n",
    "                if refresh_access_token():\n",
    "                    continue\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                status = data.get(\"status\", \"\")\n",
    "                percent = data.get(\"percent\", 0)\n",
    "                \n",
    "                if status == \"DONE\":\n",
    "                    resp = requests.get(f\"{API_BASE}/summary/{job_id}/ontology\", headers=get_headers())\n",
    "                    data2 = resp.json()\n",
    "                    return data2\n",
    "                elif status in [\"FAILED\", \"ERROR\", \"CANCEL\"]:\n",
    "                    raise Exception(f\"Job failed with status: {status}\")\n",
    "                \n",
    "                print(f\"   ⏳ {status} - {percent}%\", end=\"\\r\")\n",
    "                \n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking status: {e}\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    raise TimeoutError(f\"Timeout waiting for job {job_id}\")\n",
    "\n",
    "def get_summary_from_api(youtube_url: str, whisper_temp: float) -> str:\n",
    "    \"\"\"เรียก API สรุปของระบบ\"\"\"\n",
    "    print(f\"  Calling API with temp={whisper_temp}...\")\n",
    "    \n",
    "    try:\n",
    "        # สร้าง job\n",
    "        response = requests.post(\n",
    "            f\"{API_BASE}/summary\",\n",
    "            json={\n",
    "                \"youtubeUrl\": youtube_url,\n",
    "                \"whisperTemp\": whisper_temp\n",
    "            },\n",
    "            headers=get_headers(),\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        # ถ้า 401 ลอง refresh token แล้วลองใหม่\n",
    "        if response.status_code == 401:\n",
    "            if refresh_access_token():\n",
    "                response = requests.post(\n",
    "                    f\"{API_BASE}/summary\",\n",
    "                    json={\n",
    "                        \"youtubeUrl\": youtube_url,\n",
    "                        \"whisperTemp\": whisper_temp\n",
    "                    },\n",
    "                    headers=get_headers(),\n",
    "                    timeout=30\n",
    "                )\n",
    "        \n",
    "        if response.status_code != 200 and response.status_code != 201:\n",
    "            print(f\"  Error: {response.status_code} - {response.text}\")\n",
    "            return \"\"\n",
    "        \n",
    "        data = response.json()\n",
    "        job_id = data.get(\"jobId\")\n",
    "        \n",
    "        # ถ้า cached ก็ดึงเลย\n",
    "        if data.get(\"status\") == \"CACHED\" or data.get(\"fromCache\"):\n",
    "            print(f\"  Found cached result\")\n",
    "            result = requests.get(f\"{API_BASE}/summary/{job_id}\", headers=get_headers())\n",
    "            return result.json().get(\"summary\", \"\")\n",
    "        \n",
    "        # รอจนเสร็จ\n",
    "        print(f\"  Waiting for job {job_id}...\")\n",
    "        result = wait_for_summary(job_id)\n",
    "        return result.get(\"summary\", \"\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# ================== MAIN ==================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BERTScore Evaluation Script\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Refresh token ก่อน\n",
    "    print(\"\\n🔄 Refreshing token...\")\n",
    "    if not refresh_access_token():\n",
    "        print(\"⚠️ Warning: Could not refresh token, continuing without auth...\")\n",
    "    \n",
    "    # เก็บผลลัพธ์ทั้งหมด\n",
    "    all_results = []\n",
    "    summaries_data = []\n",
    "    \n",
    "    # 1. รัน summarization แต่ละ video และ temp\n",
    "    for url in YOUTUBE_LINKS:\n",
    "        video_id = extract_video_id(url)\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Processing: {video_id}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        video_summaries = {\"video_id\": video_id, \"url\": url}\n",
    "        \n",
    "        for temp in WHISPER_TEMPS:\n",
    "            summary = get_summary_from_api(url, temp)\n",
    "            video_summaries[f\"temp_{temp}\"] = summary\n",
    "            print(f\"  temp {temp}: {len(summary)} chars\")\n",
    "            time.sleep(2)  # delay เพื่อไม่ให้ overload\n",
    "        \n",
    "        # เพิ่ม reference summaries\n",
    "        refs = REFERENCE_SUMMARIES.get(video_id, {})\n",
    "        for tool in REF_TOOLS:\n",
    "            video_summaries[f\"ref_{tool}\"] = refs.get(tool, \"\")\n",
    "        \n",
    "        summaries_data.append(video_summaries)\n",
    "    \n",
    "    # 2. คำนวณ BERTScore\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Calculating BERTScore...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for video_data in summaries_data:\n",
    "        video_id = video_data[\"video_id\"]\n",
    "        \n",
    "        for tool in REF_TOOLS:\n",
    "            ref_summary = video_data.get(f\"ref_{tool}\", \"\")\n",
    "            if not ref_summary:\n",
    "                print(f\"  Skipping {tool} for {video_id} - no reference\")\n",
    "                continue\n",
    "            \n",
    "            for temp in WHISPER_TEMPS:\n",
    "                cand_summary = video_data.get(f\"temp_{temp}\", \"\")\n",
    "                if not cand_summary:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    P, R, F1 = score(\n",
    "                        [cand_summary],\n",
    "                        [ref_summary],\n",
    "                        lang=\"th\",\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    result = {\n",
    "                        \"video_id\": video_id,\n",
    "                        \"whisper_temp\": temp,\n",
    "                        \"reference_tool\": tool,\n",
    "                        \"precision\": round(P.mean().item(), 4),\n",
    "                        \"recall\": round(R.mean().item(), 4),\n",
    "                        \"f1\": round(F1.mean().item(), 4),\n",
    "                    }\n",
    "                    all_results.append(result)\n",
    "                    \n",
    "                    print(f\"  {video_id} | temp={temp} vs {tool}: F1={result['f1']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  Error calculating BERTScore: {e}\")\n",
    "    \n",
    "    # 3. Save to Excel\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Saving to Excel...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"evaluation_results_{timestamp}.xlsx\"\n",
    "    \n",
    "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "        # Sheet 1: BERTScore Results\n",
    "        df_results = pd.DataFrame(all_results)\n",
    "        df_results.to_excel(writer, sheet_name='BERTScore', index=False)\n",
    "        \n",
    "        # Sheet 2: All Summaries (for reference)\n",
    "        df_summaries = pd.DataFrame(summaries_data)\n",
    "        df_summaries.to_excel(writer, sheet_name='Summaries', index=False)\n",
    "        \n",
    "        # Sheet 3: Summary by Video (Pivot table style)\n",
    "        if all_results:\n",
    "            df_pivot = df_results.pivot_table(\n",
    "                values='f1',\n",
    "                index=['video_id', 'whisper_temp'],\n",
    "                columns='reference_tool',\n",
    "                aggfunc='mean'\n",
    "            ).reset_index()\n",
    "            df_pivot.to_excel(writer, sheet_name='Summary by Video', index=False)\n",
    "        \n",
    "        # Sheet 4: Average by Temp (across all videos)\n",
    "        if all_results:\n",
    "            df_avg = df_results.groupby(['whisper_temp', 'reference_tool']).agg({\n",
    "                'precision': 'mean',\n",
    "                'recall': 'mean',\n",
    "                'f1': 'mean'\n",
    "            }).reset_index()\n",
    "            df_avg.to_excel(writer, sheet_name='Average by Temp', index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Results saved to: {filename}\")\n",
    "    print(f\"   - Sheet 'BERTScore': รายละเอียดทุก comparison\")\n",
    "    print(f\"   - Sheet 'Summaries': ข้อความสรุปทั้งหมด\")\n",
    "    print(f\"   - Sheet 'Summary by Video': สรุปแยกตามวิดีโอ\")\n",
    "    print(f\"   - Sheet 'Average by Temp': ค่าเฉลี่ยแยกตาม temp\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eda46e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BERTScore Calculator\n",
      "============================================================\n",
      "\n",
      "📖 Reading: d:\\final_project_\\analysis\\evaluation_results_20260115_040144.xlsx\n",
      "   Found 2 videos\n",
      "   Columns: ['video_id', 'url', 'temp_0.0', 'temp_0.2', 'temp_0.4', 'temp_0.6', 'ref_Notta', 'ref_ChatGPT', 'ref_Gemini']\n",
      "\n",
      "============================================================\n",
      "Calculating BERTScore...\n",
      "============================================================\n",
      "\n",
      "📹 Processing: https://www.youtube.com/shorts/Mr0Fce0E7TQ\n",
      "   ✅ temp=0.0 vs Notta: F1=0.7232\n",
      "   ✅ temp=0.2 vs Notta: F1=0.7448\n",
      "   ✅ temp=0.4 vs Notta: F1=0.7677\n",
      "   ✅ temp=0.6 vs Notta: F1=0.7252\n",
      "   ✅ temp=0.0 vs ChatGPT: F1=0.6733\n",
      "   ✅ temp=0.2 vs ChatGPT: F1=0.6538\n",
      "   ✅ temp=0.4 vs ChatGPT: F1=0.7006\n",
      "   ✅ temp=0.6 vs ChatGPT: F1=0.6413\n",
      "   ✅ temp=0.0 vs Gemini: F1=0.6787\n",
      "   ✅ temp=0.2 vs Gemini: F1=0.6759\n",
      "   ✅ temp=0.4 vs Gemini: F1=0.7059\n",
      "   ✅ temp=0.6 vs Gemini: F1=0.6839\n",
      "\n",
      "📹 Processing: https://www.youtube.com/shorts/IQTOZZRi1qY\n",
      "   ✅ temp=0.0 vs Notta: F1=0.7347\n",
      "   ✅ temp=0.2 vs Notta: F1=0.7362\n",
      "   ✅ temp=0.4 vs Notta: F1=0.6529\n",
      "   ✅ temp=0.6 vs Notta: F1=0.6915\n",
      "   ✅ temp=0.0 vs ChatGPT: F1=0.6729\n",
      "   ✅ temp=0.2 vs ChatGPT: F1=0.6870\n",
      "   ✅ temp=0.4 vs ChatGPT: F1=0.6734\n",
      "   ✅ temp=0.6 vs ChatGPT: F1=0.6611\n",
      "   ✅ temp=0.0 vs Gemini: F1=0.6648\n",
      "   ✅ temp=0.2 vs Gemini: F1=0.6758\n",
      "   ✅ temp=0.4 vs Gemini: F1=0.6723\n",
      "   ✅ temp=0.6 vs Gemini: F1=0.6806\n",
      "\n",
      "============================================================\n",
      "Saving to Excel...\n",
      "============================================================\n",
      "\n",
      "✅ Results saved to: d:\\final_project_\\analysis\\evaluation_results_20260115_040144.xlsx\n",
      "   - Sheet 'BERTScore': รายละเอียดทุก comparison (24 rows)\n",
      "   - Sheet 'Summary by Video': สรุปแยกตามวิดีโอ\n",
      "   - Sheet 'Average by Temp': ค่าเฉลี่ยแยกตาม temp\n",
      "\n",
      "============================================================\n",
      "Summary\n",
      "============================================================\n",
      "\n",
      "Average F1 by Whisper Temp:\n",
      "   temp=0.0: F1=0.6913\n",
      "   temp=0.2: F1=0.6956\n",
      "   temp=0.4: F1=0.6955\n",
      "   temp=0.6: F1=0.6806\n",
      "\n",
      "Average F1 by Reference Tool:\n",
      "   ChatGPT: F1=0.6704\n",
      "   Gemini: F1=0.6797\n",
      "   Notta: F1=0.7220\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BERTScore Calculator\n",
    "อ่าน Excel file ที่มี summaries แล้วคำนวณ BERTScore\n",
    "บันทึกผลลัพธ์กลับไปใน Excel เดิม\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from bert_score import score\n",
    "import sys\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "EXCEL_FILE = r\"d:\\final_project_\\analysis\\evaluation_results_20260115_040144.xlsx\"\n",
    "WHISPER_TEMPS = [0.0, 0.2, 0.4, 0.6]\n",
    "REF_TOOLS = ['Notta', 'ChatGPT', 'Gemini']\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BERTScore Calculator\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. อ่าน Excel\n",
    "    print(f\"\\n📖 Reading: {EXCEL_FILE}\")\n",
    "    df_summaries = pd.read_excel(EXCEL_FILE, sheet_name='Summaries')\n",
    "    print(f\"   Found {len(df_summaries)} videos\")\n",
    "    print(f\"   Columns: {list(df_summaries.columns)}\")\n",
    "    \n",
    "    # 2. คำนวณ BERTScore\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Calculating BERTScore...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for idx, row in df_summaries.iterrows():\n",
    "        video_id = row['video_id']\n",
    "        print(f\"\\n📹 Processing: {video_id}\")\n",
    "        \n",
    "        for tool in REF_TOOLS:\n",
    "            ref_col = f\"ref_{tool}\"\n",
    "            ref_summary = row.get(ref_col, \"\")\n",
    "            \n",
    "            # ข้าม ref ที่ว่าง\n",
    "            if pd.isna(ref_summary) or not str(ref_summary).strip():\n",
    "                print(f\"   ⏭️ Skipping {tool} - no reference\")\n",
    "                continue\n",
    "            \n",
    "            ref_summary = str(ref_summary).strip()\n",
    "            \n",
    "            for temp in WHISPER_TEMPS:\n",
    "                temp_col = f\"temp_{temp}\"\n",
    "                cand_summary = row.get(temp_col, \"\")\n",
    "                \n",
    "                # ข้าม candidate ที่ว่าง\n",
    "                if pd.isna(cand_summary) or not str(cand_summary).strip():\n",
    "                    print(f\"   ⏭️ Skipping temp={temp} - no summary\")\n",
    "                    continue\n",
    "                \n",
    "                cand_summary = str(cand_summary).strip()\n",
    "                \n",
    "                try:\n",
    "                    P, R, F1 = score(\n",
    "                        [cand_summary],\n",
    "                        [ref_summary],\n",
    "                        lang=\"th\",\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    result = {\n",
    "                        \"video_id\": video_id,\n",
    "                        \"whisper_temp\": temp,\n",
    "                        \"reference_tool\": tool,\n",
    "                        \"precision\": round(P.mean().item(), 4),\n",
    "                        \"recall\": round(R.mean().item(), 4),\n",
    "                        \"f1\": round(F1.mean().item(), 4),\n",
    "                    }\n",
    "                    all_results.append(result)\n",
    "                    \n",
    "                    print(f\"   ✅ temp={temp} vs {tool}: F1={result['f1']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Error: {e}\")\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"\\n⚠️ No results to save!\")\n",
    "        return\n",
    "    \n",
    "    # 3. สร้าง DataFrames\n",
    "    df_results = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Pivot table แยกตาม video\n",
    "    df_pivot = df_results.pivot_table(\n",
    "        values='f1',\n",
    "        index=['video_id', 'whisper_temp'],\n",
    "        columns='reference_tool',\n",
    "        aggfunc='mean'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Average by temp\n",
    "    df_avg = df_results.groupby(['whisper_temp', 'reference_tool']).agg({\n",
    "        'precision': 'mean',\n",
    "        'recall': 'mean',\n",
    "        'f1': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 4. บันทึกกลับ Excel\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Saving to Excel...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    with pd.ExcelWriter(EXCEL_FILE, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        df_results.to_excel(writer, sheet_name='BERTScore', index=False)\n",
    "        df_pivot.to_excel(writer, sheet_name='Summary by Video', index=False)\n",
    "        df_avg.to_excel(writer, sheet_name='Average by Temp', index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Results saved to: {EXCEL_FILE}\")\n",
    "    print(f\"   - Sheet 'BERTScore': รายละเอียดทุก comparison ({len(all_results)} rows)\")\n",
    "    print(f\"   - Sheet 'Summary by Video': สรุปแยกตามวิดีโอ\")\n",
    "    print(f\"   - Sheet 'Average by Temp': ค่าเฉลี่ยแยกตาม temp\")\n",
    "    \n",
    "    # 5. แสดงสรุป\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Summary\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"\\nAverage F1 by Whisper Temp:\")\n",
    "    avg_by_temp = df_results.groupby('whisper_temp')['f1'].mean()\n",
    "    for temp, f1 in avg_by_temp.items():\n",
    "        print(f\"   temp={temp}: F1={f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nAverage F1 by Reference Tool:\")\n",
    "    avg_by_tool = df_results.groupby('reference_tool')['f1'].mean()\n",
    "    for tool, f1 in avg_by_tool.items():\n",
    "        print(f\"   {tool}: F1={f1:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
